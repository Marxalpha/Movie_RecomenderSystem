{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import pymongo\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.read_csv('./input/movies_metadata.csv',low_memory=False)\n",
    "credits_df=pd.read_csv('./input/credits.csv')\n",
    "keywords_df=pd.read_csv(\"./input/keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45466, 24) (45476, 3) (46419, 2)\n"
     ]
    }
   ],
   "source": [
    "#initial sizes\n",
    "print(movies_df.shape,credits_df.shape,keywords_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = keywords_df.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45433, 24)\n"
     ]
    }
   ],
   "source": [
    "#cleaning data\n",
    "movies_df = movies_df.drop_duplicates(subset='id')  #remove duplicates \n",
    "keywords_df = keywords_df.drop_duplicates(subset='id')\n",
    "credits_df=credits_df.drop_duplicates(subset='id')\n",
    "\n",
    "credits_df[\"id\"]=credits_df[\"id\"].astype(object)    #convert int to object type\n",
    "\n",
    "#removing non int id data\n",
    "for index,row in movies_df.iterrows():\n",
    "\ttry:\n",
    "\t\trow[\"id\"]=int(row[\"id\"])\n",
    "\texcept:\n",
    "\t\tmovies_df.drop(index,axis=0,inplace=True)\n",
    "\t\t\n",
    "movies_df[\"id\"]=pd.to_numeric(movies_df[\"id\"])      #convert string into int type\n",
    "\n",
    "#45432 \n",
    "print(movies_df.shape)\n",
    "movies_df=movies_df.dropna(subset=['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the movies,credits and keywords datafrane\n",
    "movies_copy0=pd.merge(movies_df,credits_df,how='left',right_on='id',left_on='id')\n",
    "movies_copy0=pd.merge(movies_copy0,keywords_df,how='left',right_on='id',left_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "columns_to_drop=[\"belongs_to_collection\",\"budget\",\"original_title\",\"video\",'spoken_languages','spoken_languages','production_companies',\n",
    "       'production_countries','revenue']\n",
    "movies_copy0 = movies_copy0.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after merging drop any more duplicates which exist\n",
    "movies_copy0=movies_copy0.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=movies_copy0[\"vote_average\"].mean()\n",
    "m=movies_copy0[\"vote_count\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44479, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_copy0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(x,M=m,C=c):\n",
    "    v=x['vote_count']\n",
    "    r=x['vote_average']\n",
    "    return (r*v + c*m)/(v+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['score']=movies_copy0.apply(rating,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top 3 values of the objects in the genre,cast and keywords columns\n",
    "def get_val(row):\n",
    "    dic=literal_eval(row)\n",
    "    lst=[]\n",
    "    count=0\n",
    "    for d in dic:\n",
    "        count+=1\n",
    "        lst.append(d['name'])\n",
    "        if (count==max):\n",
    "            break\n",
    "    return lst\n",
    "\n",
    "#get all the values(for keywords)\n",
    "def get_valmax(row):\n",
    "    dic=literal_eval(row)\n",
    "    lst=[]\n",
    "    for d in dic:\n",
    "        lst.append(d['name'])\n",
    "    return lst\n",
    "\n",
    "#getting only the director name from the crew\n",
    "def get_dir(row):\n",
    "    lst=[]\n",
    "    dic=literal_eval(row)\n",
    "    for i in dic:\n",
    "        if i['job']=='Director':\n",
    "            lst.append(i['name'])\n",
    "            break\n",
    "    return lst\n",
    "    # return [d['name'] for d in dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0 = movies_copy0.dropna(subset=\"crew\")\n",
    "movies_copy0=movies_copy0.dropna(subset='keywords')\n",
    "movies_copy0=movies_copy0.dropna(subset='overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44478, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_copy0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['Director']=list(movies_copy0['crew'].apply(get_dir))\n",
    "movies_copy0['cast']=movies_copy0['cast'].apply(get_val)\n",
    "movies_copy0['genres']=movies_copy0['genres'].apply(get_valmax)\n",
    "movies_copy0['keywords']=movies_copy0['keywords'].apply(get_valmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['overview']=movies_copy0['overview'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['Director']=movies_copy0['Director'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['cast'] = movies_copy0['cast'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies_copy0['genres'] = movies_copy0['genres'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies_copy0['keywords'] = movies_copy0['keywords'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies_copy0['Director']=movies_copy0['Director'].apply(lambda x:[i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fet(x):\n",
    "    return  ' '.join(x['keywords'])+' '+\" \".join(x['cast'])+' '.join(x['genres'])+\" \".join(x['Director'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['tags']=movies_copy0.apply(create_fet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['tags']=movies_copy0['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdif=CountVectorizer(max_features=20000,stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_matrix = tfdif.fit_transform(movies_copy0['tags'])\n",
    "# count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "# cosine_sim2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = pd.Series(movies_copy0.index, index = movies_copy0['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_recommendations(title, cosine_sim = cosine_sim2):\n",
    "#     idx = indices[title]\n",
    "\n",
    "#     sim_scores = list(enumerate(cosine_sim[idx]))  # Get the similarity scores of all movies wrt input movie\n",
    "#     sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)\n",
    "#     sim_scores = sim_scores[1:31]\n",
    "\n",
    "#     movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#     return movies_copy0['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_recommendations('John Wick: Chapter 2', cosine_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old over\n",
    "1.get_recommendations('John Wick', cosine_sim2)\n",
    "\n",
    "1. 28663    Kleines Arschloch - Der Film\n",
    "1. 12066                 The Dog Problem\n",
    "1. 16074             The Bread and Alley\n",
    "1. 31822               The Biscuit Eater\n",
    "1. 35244        The Spy with a Cold Nose\n",
    "1. 41104              Red Dog: True Blue\n",
    "1. 40506                     Dog Eat Dog\n",
    "1. 34697    Devil Dog: The Hound of Hell\n",
    "1. 42983                   Heavy Petting\n",
    "1. 24236             Alone For Christmas\n",
    "1. Name: title, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizerfunc(sentence):\n",
    "    return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(sen):\n",
    "    lst=[]\n",
    "    for i in sen.split():\n",
    "        lst.append(ps.stem(i))\n",
    "    return \" \".join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_copy0['l1']=movies_copy0['tags'].apply(lemmatizerfunc)\n",
    "# movies_copy0['l2']=movies_copy0['tags'].apply(stemmer)\n",
    "movies_copy0['l3']=movies_copy0['tags'].apply(lemmatize_with_postag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ran here down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_df():\n",
    "    json_data = movies_copy0.to_json(orient=\"records\")\n",
    "    records = json.loads(json_data)\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"MoviesBig\"]\n",
    "    collection = db[\"meta\"]\n",
    "    collection.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec1=tfdif.fit_transform(movies_copy0['l1']).toarray()\n",
    "# vec2=tfdif.fit_transform(movies_copy0['l2']).toarray()\n",
    "vec3=tfdif.fit_transform(movies_copy0['l3']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim1= cosine_similarity(vec1)\n",
    "# sim2= cosine_similarity(vec2)\n",
    "sim3= cosine_similarity(vec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearsons Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_rows = vec1.shape[0]\n",
    "# correlation_matrix = np.zeros((n_rows, n_rows))\n",
    "# for i in range(n_rows):\n",
    "#     for j in range(n_rows):\n",
    "#         r, p_value = pearsonr(vec1[i], vec1[j])\n",
    "#         correlation_matrix[i, j] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie,similarity):\n",
    "    movie_titles=movies_copy0['title'].values\n",
    "    if movie not in movie_titles:\n",
    "        print(movie,\"Movie not Recognized\")\n",
    "        return\n",
    "    index = movies_copy0[movies_copy0['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])\n",
    "    for i in distances[1:70]:\n",
    "        print(movies_copy0.iloc[i[0]].title , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Wick: Chapter 2 (41328, 0.2926847035024818)\n",
      "Stormheart (25370, 0.19611613513818404)\n",
      "To Kill a Man (31682, 0.19611613513818404)\n",
      "Revenge (43045, 0.19611613513818404)\n",
      "Strong Island (43840, 0.19611613513818404)\n",
      "Sexy Beast (4230, 0.179968508266339)\n",
      "Pimp Bullies (25926, 0.17541160386140586)\n",
      "Mother's Day (5051, 0.16012815380508716)\n",
      "Creature with the Atom Brain (21231, 0.16012815380508716)\n",
      "A House In The Hills (28983, 0.16012815380508716)\n",
      "Summer in the Golden Valley (37912, 0.16012815380508716)\n",
      "Detective Conan: The Fourteenth Target (39027, 0.16012815380508716)\n",
      "Run Bitch Run (40208, 0.16012815380508716)\n",
      "Wild Target (16041, 0.15384615384615385)\n",
      "Eliminators (40651, 0.15191090506254998)\n",
      "Things to Do in Denver When You're Dead (79, 0.14824986333222023)\n",
      "China Strike Force (10048, 0.14824986333222023)\n",
      "The Dagger of Kamui (11567, 0.14824986333222023)\n",
      "Ultimate Heist (30973, 0.14824986333222023)\n",
      "Essex Boys: Law of Survival (32717, 0.14824986333222023)\n",
      "Naanum Rowdydhaan (37544, 0.14824986333222023)\n",
      "The Last Bullet (37737, 0.14824986333222023)\n",
      "Trespass (7106, 0.14322297480788657)\n",
      "The Last House on Dead End Street (32070, 0.13867504905630731)\n",
      "A Friend of the Deceased (1745, 0.1386750490563073)\n",
      "The Loveless (10579, 0.1386750490563073)\n",
      "Dry Season (13365, 0.1386750490563073)\n",
      "The Bread and Alley (16074, 0.1386750490563073)\n",
      "Through and Through (17064, 0.1386750490563073)\n",
      "Contract Killer (19844, 0.1386750490563073)\n",
      "Fear No Evil (22352, 0.1386750490563073)\n",
      "And So It Is (24466, 0.1386750490563073)\n",
      "Highlander V: The Source (25714, 0.1386750490563073)\n",
      "Sweeney Todd: The Demon Barber of Fleet Street (25768, 0.1386750490563073)\n",
      "Ruby (26855, 0.1386750490563073)\n",
      "The Jinx: The Life and Deaths of Robert Durst (28854, 0.1386750490563073)\n",
      "Dead Girls (28961, 0.1386750490563073)\n",
      "The Dead Lands (29389, 0.1386750490563073)\n",
      "Crawl (32792, 0.1386750490563073)\n",
      "Night of the Seagulls (33455, 0.1386750490563073)\n",
      "Stranded (34630, 0.1386750490563073)\n",
      "Blood Widow (35679, 0.1386750490563073)\n",
      "The Suram Fortress (35694, 0.1386750490563073)\n",
      "Saving Norman (37009, 0.1386750490563073)\n",
      "The Iceman: Confessions of a Mafia Hitman (38823, 0.1386750490563073)\n",
      "Troublemaker (41320, 0.1386750490563073)\n",
      "Hailey Dean Mystery: Murder, With Love (44042, 0.1386750490563073)\n",
      "The Hitman (13745, 0.13497638119975425)\n",
      "In a Valley of Violence (40263, 0.13497638119975425)\n",
      "Massacre at Central High (15862, 0.13074409009212268)\n",
      "Kuroneko (16226, 0.13074409009212268)\n",
      "Spasmo (23953, 0.13074409009212268)\n",
      "Death Occurred Last Night (25165, 0.13074409009212268)\n",
      "J.D.'s Revenge (28097, 0.13074409009212268)\n",
      "Rolf (33414, 0.13074409009212268)\n",
      "Zero Tolerance (22372, 0.1283881477532739)\n",
      "Wild at Heart (6867, 0.12561485860426555)\n",
      "Keanu (37030, 0.1254363015010636)\n",
      "River's Edge (4072, 0.12403473458920847)\n",
      "Oh Heavenly Dog (5059, 0.12403473458920847)\n",
      "Sex and Fury (12220, 0.12403473458920847)\n",
      "A Dead Calling (13317, 0.12403473458920847)\n",
      "Angels Don't Sleep Here (20764, 0.12403473458920847)\n",
      "Bitter Feast (22720, 0.12403473458920847)\n",
      "The Equalizer (23344, 0.12403473458920847)\n",
      "Ahí está el detalle (24766, 0.12403473458920847)\n",
      "Sick Girl (24797, 0.12403473458920847)\n",
      "100 Bloody Acres (27722, 0.12403473458920847)\n",
      "Human Cobras (29469, 0.12403473458920847)\n"
     ]
    }
   ],
   "source": [
    "recommend(\"John Wick\",sim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CosineSimilarity Results\n",
    "\n",
    "## Lemmetizer Results for The Batman\n",
    "\n",
    "1. The Dark Knight\n",
    "1. The Oil, the Baby and the Transylvanians\n",
    "1. The Testimony\n",
    "1. Virtual Weapon\n",
    "1. Scarlet Eye\n",
    "1. The Last Breath\n",
    "1. Mord in Eberswalde\n",
    "1. All at Once\n",
    "1. Batman v Superman: Dawn of Justice\n",
    "1. Batman: The Dark Knight Returns, Part 1\n",
    "1. The Dark Knight Rises\n",
    "1. Batman: Under the Red Hood\n",
    "1. Helter Skelter\n",
    "1. Batman & Robin\n",
    "1. The Demolitionist\n",
    "1. Bonnie and Clyde Italian Style\n",
    "1. Nighthawks\n",
    "1. Superman\n",
    "1. Dead Man Down\n",
    "1. Batman Unmasked: The Psychology of the Dark Knight\n",
    "1. Batman Forever\n",
    "1. The Worthless\n",
    "1. The Green Hornet\n",
    "1. Blue Hill Avenue\n",
    "1. The Phenix City Story\n",
    "1. LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
    "1. Teenage Mutant Ninja Turtles\n",
    "1. The Raid 2\n",
    "1. Batman: Year One\n",
    "\n",
    "## Lemmetizer with Postag results for \"The Batman\"\n",
    "\n",
    "1. The Dark Knight\n",
    "1. The Oil, the Baby and the Transylvanians\n",
    "1. The Testimony\n",
    "1. Virtual Weapon\n",
    "1. Scarlet Eye\n",
    "1. The Last Breath\n",
    "1. Mord in Eberswalde\n",
    "1. All at Once\n",
    "1. Batman: The Dark Knight Returns, Part 1\n",
    "1. Batman & Robin\n",
    "1. Batman v Superman: Dawn of Justice\n",
    "1. The Dark Knight Rises\n",
    "1. Batman: Under the Red Hood\n",
    "1. Helter Skelter\n",
    "1. Bonnie and Clyde Italian Style\n",
    "1. The Demolitionist\n",
    "1. Superman\n",
    "1. Dead Man Down\n",
    "1. Batman Forever\n",
    "1. The Worthless\n",
    "1. The Green Hornet\n",
    "1. Blue Hill Avenue\n",
    "1. The Phenix City Story\n",
    "1. Batman Unmasked: The Psychology of the Dark Knight\n",
    "1. LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
    "1. Teenage Mutant Ninja Turtles\n",
    "1. Little Criminals\n",
    "1. Batman: Year One\n",
    "1. Batman: Bad Blood\n",
    "\n",
    "## Stemmer Tokenizer Results for \"The Batman\"\n",
    "\n",
    "1. The Dark Knight\n",
    "1. The Raid 2\n",
    "1. Superman\n",
    "1. The Avenue\n",
    "1. Beck 28 - Familjen\n",
    "1. Once Fallen\n",
    "1. Sonny\n",
    "1. Synecdoche, New York\n",
    "1. Rockaway\n",
    "1. Brother\n",
    "1. Walking Tall: The Payback\n",
    "1. Days of Santiago\n",
    "1. The Face Behind the Mask\n",
    "1. Cyclo\n",
    "1. Driven To Kill\n",
    "1. Kiwi!\n",
    "1. A Skin Too Few: The Days of Nick Drake\n",
    "1. American Me\n",
    "1. The Bastard\n",
    "1. Sexy Beast\n",
    "1. Rolling Thunder\n",
    "1. Graveyard of Honor\n",
    "1. Lockdown\n",
    "1. Run\n",
    "1. The Oil, the Baby and the Transylvanians\n",
    "1. Twelve\n",
    "1. The Testimony\n",
    "1. Virtual Weapon\n",
    "1. Scarlet Eye\n",
    "\n",
    "## Lemmetize with postag\n",
    "### Changed the dataset a bit\n",
    "1. The Dark Knight\n",
    "1. Batman: The Dark Knight Returns, Part 1\n",
    "1. Batman & Robin\n",
    "1. Batman v Superman: Dawn of Justice\n",
    "1. The Dark Knight Rises\n",
    "1. Batman: Under the Red Hood\n",
    "1. Helter Skelter\n",
    "1. Bonnie and Clyde Italian Style\n",
    "1. The Demolitionist\n",
    "1. Superman\n",
    "1. Dead Man Down\n",
    "1. Batman Forever\n",
    "1. The Worthless\n",
    "1. The Green Hornet\n",
    "1. Blue Hill Avenue\n",
    "1. The Phenix City Story\n",
    "1. Batman Unmasked: The Psychology of the Dark Knight\n",
    "1. LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
    "1. Teenage Mutant Ninja Turtles\n",
    "1. Little Criminals\n",
    "1. Batman: Year One\n",
    "1. Batman: Bad Blood\n",
    "1. Ab Tak Chhappan\n",
    "1. Human Target\n",
    "1. The Miami Story\n",
    "1. Brother\n",
    "1. Essex Boys: Law of Survival\n",
    "1. Batman Beyond: The Movie\n",
    "1. Red Dust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_movies=movies_copy0.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312         The Shawshank Redemption\n",
       "823                    The Godfather\n",
       "10276    Dilwale Dulhania Le Jayenge\n",
       "12443                The Dark Knight\n",
       "2824                      Fight Club\n",
       "                    ...             \n",
       "11522                     Epic Movie\n",
       "13523           Dragonball Evolution\n",
       "19592                            NaN\n",
       "29159                            NaN\n",
       "35008                            NaN\n",
       "Name: title, Length: 44478, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_movies['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = sorted_movies.to_json(orient=\"records\")\n",
    "records = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sorted_movies.json\", \"w\") as f:\n",
    "    json.dump(records, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendations Based on Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>score</th>\n",
       "      <th>Director</th>\n",
       "      <th>tags</th>\n",
       "      <th>l3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>[Led, by, Woody,, Andy's, toys, live, happily,...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n",
       "      <td>30-10-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>[TomHanks, TimAllen, DonRickles, JimVarney, Wa...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "      <td>7.639057</td>\n",
       "      <td>[JohnLasseter]</td>\n",
       "      <td>jealousy toy boy friendship friends rivalry bo...</td>\n",
       "      <td>jealousy toy boy friendship friends rivalry bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>[When, siblings, Judy, and, Peter, discover, a...</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n",
       "      <td>15-12-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>[RobinWilliams, JonathanHyde, KirstenDunst, Br...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[boardgame, disappearance, basedonchildren'sbo...</td>\n",
       "      <td>6.819293</td>\n",
       "      <td>[JoeJohnston]</td>\n",
       "      <td>boardgame disappearance basedonchildren'sbook ...</td>\n",
       "      <td>boardgame disappearance basedonchildren'sbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>[A, family, wedding, reignites, the, ancient, ...</td>\n",
       "      <td>11.7129</td>\n",
       "      <td>/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg</td>\n",
       "      <td>22-12-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[WalterMatthau, JackLemmon, Ann-Margret, Sophi...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[fishing, bestfriend, duringcreditsstinger, ol...</td>\n",
       "      <td>5.947230</td>\n",
       "      <td>[HowardDeutch]</td>\n",
       "      <td>fishing bestfriend duringcreditsstinger oldmen...</td>\n",
       "      <td>fish bestfriend duringcreditsstinger oldmen wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>[Cheated, on,, mistreated, and, stepped, on,, ...</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg</td>\n",
       "      <td>22-12-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[WhitneyHouston, AngelaBassett, LorettaDevine,...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>[basedonnovel, interracialrelationship, single...</td>\n",
       "      <td>5.717779</td>\n",
       "      <td>[ForestWhitaker]</td>\n",
       "      <td>basedonnovel interracialrelationship singlemot...</td>\n",
       "      <td>basedonnovel interracialrelationship singlemot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>[Just, when, George, Banks, has, recovered, fr...</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>/e64sOI48hQXyru7naBFyssKFxVd.jpg</td>\n",
       "      <td>10-02-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>[SteveMartin, DianeKeaton, MartinShort, Kimber...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[baby, midlifecrisis, confidence, aging, daugh...</td>\n",
       "      <td>5.670231</td>\n",
       "      <td>[CharlesShyer]</td>\n",
       "      <td>baby midlifecrisis confidence aging daughter m...</td>\n",
       "      <td>baby midlifecrisis confidence age daughter mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44474</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Drama, Family]</td>\n",
       "      <td>http://www.imdb.com/title/tt6209470/</td>\n",
       "      <td>439050</td>\n",
       "      <td>tt6209470</td>\n",
       "      <td>fa</td>\n",
       "      <td>[Rising, and, falling, between, a, man, and, w...</td>\n",
       "      <td>0.072051</td>\n",
       "      <td>/jldsYflnId4tTWPx8es3uzsB1I8.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Subdue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[LeilaHatami, KouroshTahami, ElhamKorda]</td>\n",
       "      <td>[{'credit_id': '5894a97d925141426c00818c', 'de...</td>\n",
       "      <td>[tragiclove]</td>\n",
       "      <td>5.629145</td>\n",
       "      <td>[HamidNematollah]</td>\n",
       "      <td>tragiclove leilahatami kouroshtahami elhamkord...</td>\n",
       "      <td>tragiclove leilahatami kouroshtahami elhamkord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44475</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111109</td>\n",
       "      <td>tt2028550</td>\n",
       "      <td>tl</td>\n",
       "      <td>[An, artist, struggles, to, finish, his, work,...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>/xZkmxsNmYXJbKVsTRLLx3pqGHx7.jpg</td>\n",
       "      <td>17-11-2011</td>\n",
       "      <td>...</td>\n",
       "      <td>Century of Birthing</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[AngelAquino, PerryDizon, HazelOrencio, JoelTo...</td>\n",
       "      <td>[{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...</td>\n",
       "      <td>[artist, play, pinoy]</td>\n",
       "      <td>5.699036</td>\n",
       "      <td>[LavDiaz]</td>\n",
       "      <td>artist play pinoy angelaquino perrydizon hazel...</td>\n",
       "      <td>artist play pinoy angelaquino perrydizon hazel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44476</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[Action, Drama, Thriller]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67758</td>\n",
       "      <td>tt0303758</td>\n",
       "      <td>en</td>\n",
       "      <td>[When, one, of, her, hits, goes, wrong,, a, pr...</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>/d5bX92nDsISNhu3ZT69uHwmfCGw.jpg</td>\n",
       "      <td>01-08-2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[ErikaEleniak, AdamBaldwin, JulieduPage, James...</td>\n",
       "      <td>[{'credit_id': '52fe4776c3a368484e0c8387', 'de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.574492</td>\n",
       "      <td>[MarkL.Lester]</td>\n",
       "      <td>erikaeleniak adambaldwin juliedupage jamesrem...</td>\n",
       "      <td>erikaeleniak adambaldwin juliedupage jamesrema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44477</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227506</td>\n",
       "      <td>tt0008536</td>\n",
       "      <td>en</td>\n",
       "      <td>[In, a, small, town, live, two, brothers,, one...</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>/aorBPO7ak8e8iJKT5OcqYxU3jlK.jpg</td>\n",
       "      <td>21-10-1917</td>\n",
       "      <td>...</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[IwanMosschuchin, NathalieLissenko, PavelPavlo...</td>\n",
       "      <td>[{'credit_id': '533bccebc3a36844cf0011a7', 'de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.639019</td>\n",
       "      <td>[YakovProtazanov]</td>\n",
       "      <td>iwanmosschuchin nathalielissenko pavelpavlov ...</td>\n",
       "      <td>iwanmosschuchin nathalielissenko pavelpavlov a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44478</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461257</td>\n",
       "      <td>tt6980792</td>\n",
       "      <td>en</td>\n",
       "      <td>[50, years, after, decriminalisation, of, homo...</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>/s5UkZt6NTsrS7ZF0Rh8nzupRlIU.jpg</td>\n",
       "      <td>09-06-2017</td>\n",
       "      <td>...</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'credit_id': '593e676c92514105b702e68e', 'de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5.639019</td>\n",
       "      <td>[DaisyAsquith]</td>\n",
       "      <td>daisyasquith</td>\n",
       "      <td>daisyasquith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44478 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult                        genres  \\\n",
       "0      FALSE   [Animation, Comedy, Family]   \n",
       "1      FALSE  [Adventure, Fantasy, Family]   \n",
       "2      FALSE             [Romance, Comedy]   \n",
       "3      FALSE      [Comedy, Drama, Romance]   \n",
       "4      FALSE                      [Comedy]   \n",
       "...      ...                           ...   \n",
       "44474  FALSE               [Drama, Family]   \n",
       "44475  FALSE                       [Drama]   \n",
       "44476  FALSE     [Action, Drama, Thriller]   \n",
       "44477  FALSE                            []   \n",
       "44478  FALSE                            []   \n",
       "\n",
       "                                   homepage      id    imdb_id  \\\n",
       "0      http://toystory.disney.com/toy-story     862  tt0114709   \n",
       "1                                       NaN    8844  tt0113497   \n",
       "2                                       NaN   15602  tt0113228   \n",
       "3                                       NaN   31357  tt0114885   \n",
       "4                                       NaN   11862  tt0113041   \n",
       "...                                     ...     ...        ...   \n",
       "44474  http://www.imdb.com/title/tt6209470/  439050  tt6209470   \n",
       "44475                                   NaN  111109  tt2028550   \n",
       "44476                                   NaN   67758  tt0303758   \n",
       "44477                                   NaN  227506  tt0008536   \n",
       "44478                                   NaN  461257  tt6980792   \n",
       "\n",
       "      original_language                                           overview  \\\n",
       "0                    en  [Led, by, Woody,, Andy's, toys, live, happily,...   \n",
       "1                    en  [When, siblings, Judy, and, Peter, discover, a...   \n",
       "2                    en  [A, family, wedding, reignites, the, ancient, ...   \n",
       "3                    en  [Cheated, on,, mistreated, and, stepped, on,, ...   \n",
       "4                    en  [Just, when, George, Banks, has, recovered, fr...   \n",
       "...                 ...                                                ...   \n",
       "44474                fa  [Rising, and, falling, between, a, man, and, w...   \n",
       "44475                tl  [An, artist, struggles, to, finish, his, work,...   \n",
       "44476                en  [When, one, of, her, hits, goes, wrong,, a, pr...   \n",
       "44477                en  [In, a, small, town, live, two, brothers,, one...   \n",
       "44478                en  [50, years, after, decriminalisation, of, homo...   \n",
       "\n",
       "      popularity                       poster_path release_date  ...  \\\n",
       "0      21.946943  /rhIRbceoE9lR4veEXuwCC2wARtG.jpg   30-10-1995  ...   \n",
       "1      17.015539  /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg   15-12-1995  ...   \n",
       "2        11.7129  /6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg   22-12-1995  ...   \n",
       "3       3.859495  /16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg   22-12-1995  ...   \n",
       "4       8.387519  /e64sOI48hQXyru7naBFyssKFxVd.jpg   10-02-1995  ...   \n",
       "...          ...                               ...          ...  ...   \n",
       "44474   0.072051  /jldsYflnId4tTWPx8es3uzsB1I8.jpg          NaN  ...   \n",
       "44475   0.178241  /xZkmxsNmYXJbKVsTRLLx3pqGHx7.jpg   17-11-2011  ...   \n",
       "44476   0.903007  /d5bX92nDsISNhu3ZT69uHwmfCGw.jpg   01-08-2003  ...   \n",
       "44477   0.003503  /aorBPO7ak8e8iJKT5OcqYxU3jlK.jpg   21-10-1917  ...   \n",
       "44478   0.163015  /s5UkZt6NTsrS7ZF0Rh8nzupRlIU.jpg   09-06-2017  ...   \n",
       "\n",
       "                             title vote_average vote_count  \\\n",
       "0                        Toy Story          7.7     5415.0   \n",
       "1                          Jumanji          6.9     2413.0   \n",
       "2                 Grumpier Old Men          6.5       92.0   \n",
       "3                Waiting to Exhale          6.1       34.0   \n",
       "4      Father of the Bride Part II          5.7      173.0   \n",
       "...                            ...          ...        ...   \n",
       "44474                       Subdue          4.0        1.0   \n",
       "44475          Century of Birthing          9.0        3.0   \n",
       "44476                     Betrayal          3.8        6.0   \n",
       "44477             Satan Triumphant          0.0        0.0   \n",
       "44478                     Queerama          0.0        0.0   \n",
       "\n",
       "                                                    cast  \\\n",
       "0      [TomHanks, TimAllen, DonRickles, JimVarney, Wa...   \n",
       "1      [RobinWilliams, JonathanHyde, KirstenDunst, Br...   \n",
       "2      [WalterMatthau, JackLemmon, Ann-Margret, Sophi...   \n",
       "3      [WhitneyHouston, AngelaBassett, LorettaDevine,...   \n",
       "4      [SteveMartin, DianeKeaton, MartinShort, Kimber...   \n",
       "...                                                  ...   \n",
       "44474           [LeilaHatami, KouroshTahami, ElhamKorda]   \n",
       "44475  [AngelAquino, PerryDizon, HazelOrencio, JoelTo...   \n",
       "44476  [ErikaEleniak, AdamBaldwin, JulieduPage, James...   \n",
       "44477  [IwanMosschuchin, NathalieLissenko, PavelPavlo...   \n",
       "44478                                                 []   \n",
       "\n",
       "                                                    crew  \\\n",
       "0      [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1      [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2      [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3      [{'credit_id': '52fe44779251416c91011acb', 'de...   \n",
       "4      [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "...                                                  ...   \n",
       "44474  [{'credit_id': '5894a97d925141426c00818c', 'de...   \n",
       "44475  [{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...   \n",
       "44476  [{'credit_id': '52fe4776c3a368484e0c8387', 'de...   \n",
       "44477  [{'credit_id': '533bccebc3a36844cf0011a7', 'de...   \n",
       "44478  [{'credit_id': '593e676c92514105b702e68e', 'de...   \n",
       "\n",
       "                                                keywords     score  \\\n",
       "0      [jealousy, toy, boy, friendship, friends, riva...  7.639057   \n",
       "1      [boardgame, disappearance, basedonchildren'sbo...  6.819293   \n",
       "2      [fishing, bestfriend, duringcreditsstinger, ol...  5.947230   \n",
       "3      [basedonnovel, interracialrelationship, single...  5.717779   \n",
       "4      [baby, midlifecrisis, confidence, aging, daugh...  5.670231   \n",
       "...                                                  ...       ...   \n",
       "44474                                       [tragiclove]  5.629145   \n",
       "44475                              [artist, play, pinoy]  5.699036   \n",
       "44476                                                 []  5.574492   \n",
       "44477                                                 []  5.639019   \n",
       "44478                                                 []  5.639019   \n",
       "\n",
       "                Director                                               tags  \\\n",
       "0         [JohnLasseter]  jealousy toy boy friendship friends rivalry bo...   \n",
       "1          [JoeJohnston]  boardgame disappearance basedonchildren'sbook ...   \n",
       "2         [HowardDeutch]  fishing bestfriend duringcreditsstinger oldmen...   \n",
       "3       [ForestWhitaker]  basedonnovel interracialrelationship singlemot...   \n",
       "4         [CharlesShyer]  baby midlifecrisis confidence aging daughter m...   \n",
       "...                  ...                                                ...   \n",
       "44474  [HamidNematollah]  tragiclove leilahatami kouroshtahami elhamkord...   \n",
       "44475          [LavDiaz]  artist play pinoy angelaquino perrydizon hazel...   \n",
       "44476     [MarkL.Lester]   erikaeleniak adambaldwin juliedupage jamesrem...   \n",
       "44477  [YakovProtazanov]   iwanmosschuchin nathalielissenko pavelpavlov ...   \n",
       "44478     [DaisyAsquith]                                       daisyasquith   \n",
       "\n",
       "                                                      l3  \n",
       "0      jealousy toy boy friendship friends rivalry bo...  \n",
       "1      boardgame disappearance basedonchildren'sbook ...  \n",
       "2      fish bestfriend duringcreditsstinger oldmen wa...  \n",
       "3      basedonnovel interracialrelationship singlemot...  \n",
       "4      baby midlifecrisis confidence age daughter mot...  \n",
       "...                                                  ...  \n",
       "44474  tragiclove leilahatami kouroshtahami elhamkord...  \n",
       "44475  artist play pinoy angelaquino perrydizon hazel...  \n",
       "44476  erikaeleniak adambaldwin juliedupage jamesrema...  \n",
       "44477  iwanmosschuchin nathalielissenko pavelpavlov a...  \n",
       "44478                                       daisyasquith  \n",
       "\n",
       "[44478 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_copy0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genrelst(x):\n",
    "    return ' '.join(x['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genres'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movies_copy0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenrelst\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mmovies_copy0\u001b[38;5;241m.\u001b[39mapply(create_genrelst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:8845\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8834\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8836\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   8837\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8838\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8843\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   8844\u001b[0m )\n\u001b[1;32m-> 8845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 857\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    875\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    876\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    877\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [52], line 2\u001b[0m, in \u001b[0;36mcreate_genrelst\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_genrelst\u001b[39m(x):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'"
     ]
    }
   ],
   "source": [
    "movies_copy0['genrelst']=movies_copy0.apply(create_genrelst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_copy0['gl3']=movies_copy0['genrelst'].apply(lemmatize_with_postag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
